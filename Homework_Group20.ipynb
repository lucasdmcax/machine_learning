{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47693163",
   "metadata": {},
   "source": [
    "<a id=\"import-data\"></a>\n",
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891cffd7",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "## Table of Contents\n",
    "- [Import Data](#import-data)\n",
    "- [Data Exploration](#data-exploration)\n",
    "  - [Categorical Features](#categorical-features)\n",
    "  - [Numerical Features](#numerical-features)\n",
    "  - [Plots](#plots)\n",
    "- [Pre-processing](#pre-processing)\n",
    "  - [Missing Values](#missing-values)\n",
    "  - [String Distance](#string-distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# to calculate distance between strings\n",
    "from thefuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6468f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv').set_index('carID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc133ea3-1850-4386-ab5e-6db9950c48f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c607395",
   "metadata": {},
   "source": [
    "#### Import Data Summary\n",
    "- Dataset loaded successfully with `carID` as the index\n",
    "- The dataset contains information about cars including both numerical features (price, mileage, tax, etc.) and categorical features (brand, model, transmission, etc.)\n",
    "- Initial inspection shows multiple features that will require preprocessing:\n",
    "  - Numerical features that need cleaning (negative values, outliers)\n",
    "  - Categorical features that need standardization\n",
    "  - Presence of missing values in several columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3db49c",
   "metadata": {},
   "source": [
    "<a id=\"data-exploration\"></a>\n",
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0273ca",
   "metadata": {},
   "source": [
    "<a id=\"categorical-features\"></a>\n",
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432c021",
   "metadata": {},
   "source": [
    "#### Check Categorical Features Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7675d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicated_ids = df.index.duplicated().sum()\n",
    "print(f'Number of duplicated carIDs: {num_duplicated_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical features\n",
    "cat_cols = ['Brand', 'model', 'fuelType', 'transmission']\n",
    "\n",
    "cat_outliers_examples = {col: df[col].value_counts().tail(10).index for col in cat_cols}\n",
    "\n",
    "pd.DataFrame(cat_outliers_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['hasDamage'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa457064",
   "metadata": {},
   "source": [
    "#### Categorical Features Summary\n",
    "- Initial analysis reveals significant data quality issues across all categorical columns\n",
    "- No standardization in categorical features, with multiple variations of the same values (different spellings, capitalizations)\n",
    "- The `hasDamage` feature shows concerning data quality, containing only 0's and NA values\n",
    "- Solution: We will implement string distance-based standardization using the `thefuzz` library to clean and standardize these features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab1e0a",
   "metadata": {},
   "source": [
    "<a id=\"numerical-features\"></a>\n",
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical features\n",
    "num_cols = [ 'mileage', 'tax', 'mpg', 'engineSize', 'year']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d6909",
   "metadata": {},
   "source": [
    "<a id=\"plots\"></a>\n",
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['price', 'mileage', 'tax', 'mpg', 'engineSize', 'year']\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.boxplot(data=df, x=col, color=\"skyblue\")\n",
    "    plt.title(f\"Boxplot of {col}\", fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(data=df, x=col, bins=30, kde=True, color=\"lightcoral\")\n",
    "    plt.title(f\"Distribution of {col}\", fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f2c3cb",
   "metadata": {},
   "source": [
    "<a id=\"pre-processing\"></a>\n",
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"price\"])   \n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Validation set size: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = X_train.copy()\n",
    "X_val_clean = X_val.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009118e1",
   "metadata": {},
   "source": [
    "<a id=\"missing-values\"></a>\n",
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57589a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_general = [\"tax\", \"previousOwners\", \"paintQuality%\", \"engineSize\"]\n",
    "\n",
    "median_imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train_clean[num_general] = median_imputer.fit_transform(X_train_clean[num_general])\n",
    "X_val_clean[num_general] = median_imputer.transform(X_val_clean[num_general])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"mpg\" in X_train_clean.columns and \"fuelType\" in X_train_clean.columns:\n",
    "    mpg_group_medians = X_train_clean.groupby(\"fuelType\")[\"mpg\"].median()\n",
    "\n",
    "    def impute_mpg(row):\n",
    "        if pd.isnull(row[\"mpg\"]):\n",
    "            return mpg_group_medians.get(row[\"fuelType\"], X_train_clean[\"mpg\"].median())\n",
    "        return row[\"mpg\"]\n",
    "\n",
    "    X_train_clean[\"mpg\"] = X_train_clean.apply(impute_mpg, axis=1)\n",
    "    X_val_clean[\"mpg\"] = X_val_clean.apply(impute_mpg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_general = [\"Brand\", \"model\", \"transmission\", \"fuelType\"]\n",
    "\n",
    "mode_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X_train_clean[cat_general] = mode_imputer.fit_transform(X_train_clean[cat_general])\n",
    "X_val_clean[cat_general] = mode_imputer.transform(X_val_clean[cat_general])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e879bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"hasDamage\" in X_train_clean.columns:\n",
    "    X_train_clean[\"hasDamage\"] = X_train_clean[\"hasDamage\"].fillna(\"Unknown\")\n",
    "    X_val_clean[\"hasDamage\"] = X_val_clean[\"hasDamage\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_summary_train = X_train_clean.isnull().sum()\n",
    "missing_summary_val = X_val_clean.isnull().sum()\n",
    "\n",
    "print(\"Remaining missing values (train):\", missing_summary_train.sum())\n",
    "print(\"Remaining missing values (validation):\", missing_summary_val.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64917c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_missing = X_train_clean.isnull().sum()\n",
    "remaining_missing = remaining_missing[remaining_missing > 0]\n",
    "print(\"Columns with remaining NaN values:\")\n",
    "display(remaining_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68574331",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"year\", \"mileage\", \"mpg\"]:\n",
    "    if col in X_train_clean.columns:\n",
    "        median_value = X_train_clean[col].median()\n",
    "        X_train_clean[col].fillna(median_value, inplace=True)\n",
    "        X_val_clean[col].fillna(median_value, inplace=True)\n",
    "\n",
    "remaining_missing = X_train_clean.isnull().sum()\n",
    "remaining_missing = remaining_missing[remaining_missing > 0]\n",
    "print(\"Columns with remaining NaN values after final cleaning:\")\n",
    "display(remaining_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c931a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_missing = X_train_clean.isnull().sum()\n",
    "remaining_missing = remaining_missing[remaining_missing > 0]\n",
    "print(\"Columns with remaining NaN values:\")\n",
    "display(remaining_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f021430",
   "metadata": {},
   "source": [
    "### Numeric Features\n",
    "\n",
    "- carID\n",
    "- year\n",
    "- price\n",
    "- mileage\n",
    "- tax\n",
    "- mpg\n",
    "- engineSize\n",
    "- paintQuality\n",
    "- previousOwners\n",
    "- hasDamage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are negative features that should not be negative\n",
    "numeric_features = X_train_clean.select_dtypes(include=['int64', 'float64']).columns\n",
    "negative_values = {}\n",
    "for col in numeric_features:\n",
    "    negative_count = (X_train_clean[col] < 0).sum()\n",
    "    if negative_count > 0:\n",
    "        negative_values[col] = negative_count   \n",
    "\n",
    "for v in negative_values:\n",
    "    print(f\"Feature '{v}' has {negative_values[v]} negative values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b96ea6",
   "metadata": {},
   "source": [
    "### Strategy:\n",
    "\n",
    "- Change negative values to `NaN`\n",
    "- Remove extreme outliers\n",
    "- Impute using the appropriate method (median, mode, or group-based)\n",
    "- Convert the column back to integer type if applicable\n",
    "\n",
    "Note: Still have to choose what method to use to change the missing values in the feature \"hasDamage\" before I can switch from float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_fix = list(negative_values.keys())\n",
    "\n",
    "for feature in cols_to_fix:\n",
    "    X_train_clean.loc[X_train_clean[feature] < 0, feature] = np.nan\n",
    "    X_val_clean.loc[X_val_clean[feature] < 0, feature] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8891fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train_clean.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    q1 = X_train_clean[col].quantile(0.25)\n",
    "    q3 = X_train_clean[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_lim = q1 - (1.5 * iqr)\n",
    "    upper_lim = q3 + (1.5 * iqr)\n",
    "    X_train_clean[col] = X_train_clean[col].mask((X_train_clean[col] < lower_lim) | (X_train_clean[col] > upper_lim), np.nan)\n",
    "    X_val_clean[col] = X_val_clean[col].mask((X_val_clean[col] < lower_lim) | (X_val_clean[col] > upper_lim), np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e8be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cols_to_fix:\n",
    "    median_value = X_train_clean[feature].median()\n",
    "    X_train_clean[feature].fillna(median_value, inplace=True)\n",
    "    X_val_clean[feature].fillna(median_value, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = ['year', 'previousOwners']\n",
    "\n",
    "median_year = X_train_clean['year'].median()\n",
    "X_train_clean['year'].fillna(median_year, inplace=True)\n",
    "X_val_clean['year'].fillna(median_year, inplace=True)\n",
    "\n",
    "for feature in int_cols:\n",
    "    X_train_clean[feature] = X_train_clean[feature].astype(int)\n",
    "    X_val_clean[feature] = X_val_clean[feature].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f72094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_clean[\"year\"] < 1950).sum() and (X_train_clean[\"year\"] > 2025).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7231b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cdd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b97892",
   "metadata": {},
   "source": [
    "Final check for nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391910c",
   "metadata": {},
   "source": [
    "Check for other strange values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53565667",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of percentages above 100: {(X_train_clean[\"paintQuality%\"] > 100).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean.loc[(X_train_clean['paintQuality%'] > 100), 'paintQuality%'] = np.nan\n",
    "X_val_clean.loc[(X_val_clean['paintQuality%'] > 100), 'paintQuality%'] = np.nan\n",
    "\n",
    "median_paint = X_train_clean['paintQuality%'].median()\n",
    "X_train_clean['paintQuality%'].fillna(median_paint, inplace=True)\n",
    "X_val_clean['paintQuality%'].fillna(median_paint, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = X_train_clean.isnull().sum()\n",
    "missing_percent = (missing_counts / len(df)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Count\": missing_counts,\n",
    "    \"Missing %\": missing_percent.round(2)\n",
    "}).sort_values(by=\"Missing %\", ascending=False)\n",
    "\n",
    "missing_summary[missing_summary[\"Missing Count\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66054541",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train_clean.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "outlier_summary = []\n",
    "\n",
    "for col in num_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = X_train_clean[(X_train_clean[col] < lower_bound) | (X_train_clean[col] > upper_bound)]\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        \"Feature\": col,\n",
    "        \"Lower Bound\": round(lower_bound, 2),\n",
    "        \"Upper Bound\": round(upper_bound, 2),\n",
    "        \"Outlier Count\": len(outliers),\n",
    "        \"Outlier %\": round(len(outliers) / len(df) * 100, 2)\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values(by=\"Outlier %\", ascending=False)\n",
    "outlier_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5f69a",
   "metadata": {},
   "source": [
    "<a id=\"string-distances\"></a>\n",
    "# Calculating the string distances\n",
    "to standardize the column strings that have misspelled names using the library \"thefuzz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1655849",
   "metadata": {},
   "source": [
    "First we are standarlizing the brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e91d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faa4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brands = [\"volkswagen\", \"ford\", \"fiat\", \"volksvagen\", \"wolkswagen\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAND_COL = \"Brand\"   \n",
    "ANCHOR_NUM = 9            # top 10 k most frequent ancor\n",
    "SIM_THRESHOLD = 85\n",
    "\n",
    "# threshold for fuzzy matching\n",
    "SIM_THRESHOLD = 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d009447",
   "metadata": {},
   "outputs": [],
   "source": [
    "_brand_norm = X_train_clean[BRAND_COL].astype(str)   # make it shure that is a string\n",
    "_brand_norm = _brand_norm.str.strip()                # remove extra spaces\n",
    "_brand_norm = _brand_norm.str.lower()                # to lower case\n",
    "\n",
    "df[\"Brand\"].str.lower().value_counts() #analysing the most frequent brand names in our datasety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c32fd6c",
   "metadata": {},
   "source": [
    "Now we get the most common brand names as we analysed before and create a map dictionary for corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2132533",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = _brand_norm.value_counts().head(ANCHOR_NUM).index.tolist()\n",
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7037a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mapping = {}\n",
    "\n",
    "# for each unique brand, find the closest anchor and map if similarity is high\n",
    "for val in _brand_norm.unique():\n",
    "    if val in anchors:\n",
    "        continue  # already a good brand\n",
    "    match, score = process.extractOne(val, anchors, scorer=fuzz.token_set_ratio)\n",
    "    if score >= SIM_THRESHOLD:\n",
    "        mapping[val] = match  # map wrong/rare brand to correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d25d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean[\"brand_clean\"] = _brand_norm.map(lambda x: mapping.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d630362",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean[\"brand_clean\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
